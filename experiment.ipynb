{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shayan/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "import openai\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser\n",
    "from eval.args import RunnerArguments, HFArguments, OAIArguments, GenerationArguments\n",
    "from eval.evaluator import HFEvaluator, OAIEvaluator\n",
    "from eval.tasks import ALL_TASKS, get_task\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "task = get_task('proofwriter-neurosymbolic-2shot')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a first-order logic (FOL) problem.\n",
      "The problem is to determine whether the conclusion follows from the premises.\n",
      "The premises are given in the form of a set of first-order logic sentences.\n",
      "The conclusion is given in the form of a single first-order logic sentence.\n",
      "The task is to translate each of the premises and conclusions into FOL expressions, so that the expressions can be evaluated by a theorem solver to determine whether the conclusion follows from the premises.\n",
      "Expressions should be adhere to the format of the Python NLTK package logic module.\n",
      "\n",
      "\n",
      "<PREMISES>\n",
      "All dispensable things are environment-friendly.\n",
      "All woodware is dispensable.\n",
      "All paper is woodware.\n",
      "No good things are bad.\n",
      "All environment-friendly things are good.\n",
      "A worksheet is either paper or is environment-friendly.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "A worksheet is not dispensable.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "TEXT:\tAll dispensable things are environment-friendly.\n",
      "FOL:\tall x. (Dispensable(x) -> EnvironmentFriendly(x))\n",
      "TEXT:\tAll woodware is dispensable.\n",
      "FOL:\tall x. (Woodware(x) -> Dispensable(x))\n",
      "TEXT:\tAll paper is woodware.\n",
      "FOL:\tall x. (Paper(x) -> Woodware(x))\n",
      "TEXT:\tNo good things are bad.\n",
      "FOL:\tall x. (Good(x) -> -Bad(x))\n",
      "TEXT:\tAll environment-friendly things are good.\n",
      "FOL:\tall x. (EnvironmentFriendly(x) -> Good(x))\n",
      "TEXT:\tA worksheet is either paper or is environment-friendly.\n",
      "FOL:\t((Paper(Worksheet) & -EnvironmentFriendly(Worksheet)) | (-Paper(Worksheet) & EnvironmentFriendly(Worksheet)))\n",
      "TEXT:\tA worksheet is not dispensable.\n",
      "FOL:\t-Dispensable(Worksheet)\n",
      "</EVALUATE>\n",
      "\n",
      "<PREMISES>\n",
      "A La Liga soccer team ranks higher than another if it receives more points.\n",
      "If two La Liga soccer teams recieve the same points, the team which recieves more points from the games between the two teams ranks higher.\n",
      "Real Madrid and Barcelona are both La Liga soccer teams.\n",
      "In La Liga 2021-2022, Real Madrid recieves 86 points and Barcelon recieves 73 points.\n",
      "In La Liga 2021-2022, Real Madrid and Barcelona both recieve 3 points from the games between them.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "In La Liga 2021-2022, Real Madrid ranks higher than Barcelona.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "TEXT:\tA La Liga soccer team ranks higher than another if it receives more points.\n",
      "FOL:\tall x. all y. (LaLiga(x) & LaLiga(y) & MorePoints(x, y) -> HigherRank(x, y))\n",
      "TEXT:\tIf two La Liga soccer teams recieve the same points, the team which recieves more points from the games between the two teams ranks higher.\n",
      "FOL:\tall x. all y. (LaLiga(x) & LaLiga(y) & -MorePoints(x, y) & -MorePoints(y, x) & MorePointsInGameBetween(x, y) -> HigherRank(x, y))\n",
      "TEXT:\tReal Madrid and Barcelona are both La Liga soccer teams.\n",
      "FOL:\tLaLiga(RealMadrid) & LaLiga(Barcelona)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid recieves 86 points and Barcelon recieves 73 points.\n",
      "FOL:\tMorePoints(RealMadrid, Barcelona)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid and Barcelona both recieve 3 points from the games between them.\n",
      "FOL:\t-MorePointsInGameBetween(RealMadrid, Barcelona) & -MorePointsInGameBetween(Barcelona, RealMadrid)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid ranks higher than Barcelona.\n",
      "FOL:\tHigherRank(RealMadrid, Barcelona)\n",
      "</EVALUATE>\n",
      "\n",
      "<PREMISES>\n",
      "The bear eats the dog.\n",
      "The bear eats the rabbit.\n",
      "The bear is round.\n",
      "The bear needs the rabbit.\n",
      "The bear needs the tiger.\n",
      "The bear sees the rabbit.\n",
      "The dog eats the bear.\n",
      "The rabbit eats the tiger.\n",
      "The rabbit is round.\n",
      "The tiger eats the bear.\n",
      "The tiger is cold.\n",
      "The tiger is young.\n",
      "If something eats the tiger then the tiger needs the dog.\n",
      "If the bear sees the dog and the dog eats the tiger then the dog eats the bear.\n",
      "If something eats the bear then it sees the tiger.\n",
      "If the tiger sees the rabbit then the rabbit eats the bear.\n",
      "If something eats the bear and the bear sees the rabbit then it sees the dog.\n",
      "If something sees the dog then it sees the rabbit.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "The tiger eats the dog.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task.get_prompt(task.get_dataset()[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    runner_args = RunnerArguments()\n",
    "    hf_args = HFArguments()\n",
    "    oai_args = OAIArguments()\n",
    "    gen_args = GenerationArguments()\n",
    "    args = HfArgumentParser([runner_args, hf_args, oai_args, gen_args]).parse_args(\"\")\n",
    "\n",
    "    args.output_dir = pathlib.Path(os.getcwd()).parent / args.output_dir\n",
    "    args.save_generations_raw_path = args.output_dir / args.save_generations_raw_path\n",
    "    args.save_generations_prc_path = args.output_dir / args.save_generations_prc_path\n",
    "    args.save_references_path = args.output_dir / args.save_references_path\n",
    "    args.save_results_path = args.output_dir / args.save_results_path\n",
    "    args.save_generations_raw_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    args.save_generations_prc_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    args.save_references_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    args.save_results_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    args.openai_api_env_keys = ['OPENAI_API_KEY']\n",
    "    args.model = 'gpt-3.5-turbo'\n",
    "    return args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "task = get_task('proofwriter-neurosymbolic-2shot')\n",
    "evaluator = OAIEvaluator(args, chat=True)\n",
    "dataset = task.get_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant that carefully follows instructions. You should complete the user text, continuing from the example format, rather than providing a conversational response.\n"
     ]
    }
   ],
   "source": [
    "print(args.chat_system_instruction)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a first-order logic (FOL) problem.\n",
      "The problem is to determine whether the conclusion follows from the premises.\n",
      "The premises are given in the form of a set of first-order logic sentences.\n",
      "The conclusion is given in the form of a single first-order logic sentence.\n",
      "The task is to translate each of the premises and conclusions into FOL expressions, so that the expressions can be evaluated by a theorem solver to determine whether the conclusion follows from the premises.\n",
      "Expressions should be adhere to the format of the Python NLTK package logic module.\n",
      "\n",
      "\n",
      "<PREMISES>\n",
      "All dispensable things are environment-friendly.\n",
      "All woodware is dispensable.\n",
      "All paper is woodware.\n",
      "No good things are bad.\n",
      "All environment-friendly things are good.\n",
      "A worksheet is either paper or is environment-friendly.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "A worksheet is not dispensable.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "TEXT:\tAll dispensable things are environment-friendly.\n",
      "FOL:\tall x. (Dispensable(x) -> EnvironmentFriendly(x))\n",
      "TEXT:\tAll woodware is dispensable.\n",
      "FOL:\tall x. (Woodware(x) -> Dispensable(x))\n",
      "TEXT:\tAll paper is woodware.\n",
      "FOL:\tall x. (Paper(x) -> Woodware(x))\n",
      "TEXT:\tNo good things are bad.\n",
      "FOL:\tall x. (Good(x) -> -Bad(x))\n",
      "TEXT:\tAll environment-friendly things are good.\n",
      "FOL:\tall x. (EnvironmentFriendly(x) -> Good(x))\n",
      "TEXT:\tA worksheet is either paper or is environment-friendly.\n",
      "FOL:\t((Paper(Worksheet) & -EnvironmentFriendly(Worksheet)) | (-Paper(Worksheet) & EnvironmentFriendly(Worksheet)))\n",
      "TEXT:\tA worksheet is not dispensable.\n",
      "FOL:\t-Dispensable(Worksheet)\n",
      "</EVALUATE>\n",
      "\n",
      "<PREMISES>\n",
      "A La Liga soccer team ranks higher than another if it receives more points.\n",
      "If two La Liga soccer teams recieve the same points, the team which recieves more points from the games between the two teams ranks higher.\n",
      "Real Madrid and Barcelona are both La Liga soccer teams.\n",
      "In La Liga 2021-2022, Real Madrid recieves 86 points and Barcelon recieves 73 points.\n",
      "In La Liga 2021-2022, Real Madrid and Barcelona both recieve 3 points from the games between them.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "In La Liga 2021-2022, Real Madrid ranks higher than Barcelona.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "TEXT:\tA La Liga soccer team ranks higher than another if it receives more points.\n",
      "FOL:\tall x. all y. (LaLiga(x) & LaLiga(y) & MorePoints(x, y) -> HigherRank(x, y))\n",
      "TEXT:\tIf two La Liga soccer teams recieve the same points, the team which recieves more points from the games between the two teams ranks higher.\n",
      "FOL:\tall x. all y. (LaLiga(x) & LaLiga(y) & -MorePoints(x, y) & -MorePoints(y, x) & MorePointsInGameBetween(x, y) -> HigherRank(x, y))\n",
      "TEXT:\tReal Madrid and Barcelona are both La Liga soccer teams.\n",
      "FOL:\tLaLiga(RealMadrid) & LaLiga(Barcelona)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid recieves 86 points and Barcelon recieves 73 points.\n",
      "FOL:\tMorePoints(RealMadrid, Barcelona)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid and Barcelona both recieve 3 points from the games between them.\n",
      "FOL:\t-MorePointsInGameBetween(RealMadrid, Barcelona) & -MorePointsInGameBetween(Barcelona, RealMadrid)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid ranks higher than Barcelona.\n",
      "FOL:\tHigherRank(RealMadrid, Barcelona)\n",
      "</EVALUATE>\n",
      "\n",
      "<PREMISES>\n",
      "The bear eats the dog.\n",
      "The bear eats the rabbit.\n",
      "The bear is round.\n",
      "The bear needs the rabbit.\n",
      "The bear needs the tiger.\n",
      "The bear sees the rabbit.\n",
      "The dog eats the bear.\n",
      "The rabbit eats the tiger.\n",
      "The rabbit is round.\n",
      "The tiger eats the bear.\n",
      "The tiger is cold.\n",
      "The tiger is young.\n",
      "If something eats the tiger then the tiger needs the dog.\n",
      "If the bear sees the dog and the dog eats the tiger then the dog eats the bear.\n",
      "If something eats the bear then it sees the tiger.\n",
      "If the tiger sees the rabbit then the rabbit eats the bear.\n",
      "If something eats the bear and the bear sees the rabbit then it sees the dog.\n",
      "If something sees the dog then it sees the rabbit.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "The tiger eats the dog.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = evaluator.get_completion(\n",
    "    prompt=task.get_prompt(dataset[0]),\n",
    "    stop=task.stop_words\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "linc-kernel",
   "language": "python",
   "display_name": "linc-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
