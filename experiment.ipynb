{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shayan/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "import openai\n",
    "import datasets\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, HfArgumentParser\n",
    "from eval.args import RunnerArguments, HFArguments, OAIArguments, GenerationArguments\n",
    "from eval.evaluator import HFEvaluator, OAIEvaluator\n",
    "from eval.tasks import ALL_TASKS, get_task\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "transformers.logging.set_verbosity_error()\n",
    "datasets.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "task = get_task('proofwriter-neurosymbolic-2shot')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a first-order logic (FOL) problem.\n",
      "The problem is to determine whether the conclusion follows from the premises.\n",
      "The premises are given in the form of a set of first-order logic sentences.\n",
      "The conclusion is given in the form of a single first-order logic sentence.\n",
      "The task is to translate each of the premises and conclusions into FOL expressions, so that the expressions can be evaluated by a theorem solver to determine whether the conclusion follows from the premises.\n",
      "Expressions should be adhere to the format of the Python NLTK package logic module.\n",
      "\n",
      "\n",
      "<PREMISES>\n",
      "All dispensable things are environment-friendly.\n",
      "All woodware is dispensable.\n",
      "All paper is woodware.\n",
      "No good things are bad.\n",
      "All environment-friendly things are good.\n",
      "A worksheet is either paper or is environment-friendly.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "A worksheet is not dispensable.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "TEXT:\tAll dispensable things are environment-friendly.\n",
      "FOL:\tall x. (Dispensable(x) -> EnvironmentFriendly(x))\n",
      "TEXT:\tAll woodware is dispensable.\n",
      "FOL:\tall x. (Woodware(x) -> Dispensable(x))\n",
      "TEXT:\tAll paper is woodware.\n",
      "FOL:\tall x. (Paper(x) -> Woodware(x))\n",
      "TEXT:\tNo good things are bad.\n",
      "FOL:\tall x. (Good(x) -> -Bad(x))\n",
      "TEXT:\tAll environment-friendly things are good.\n",
      "FOL:\tall x. (EnvironmentFriendly(x) -> Good(x))\n",
      "TEXT:\tA worksheet is either paper or is environment-friendly.\n",
      "FOL:\t((Paper(Worksheet) & -EnvironmentFriendly(Worksheet)) | (-Paper(Worksheet) & EnvironmentFriendly(Worksheet)))\n",
      "TEXT:\tA worksheet is not dispensable.\n",
      "FOL:\t-Dispensable(Worksheet)\n",
      "</EVALUATE>\n",
      "\n",
      "<PREMISES>\n",
      "A La Liga soccer team ranks higher than another if it receives more points.\n",
      "If two La Liga soccer teams recieve the same points, the team which recieves more points from the games between the two teams ranks higher.\n",
      "Real Madrid and Barcelona are both La Liga soccer teams.\n",
      "In La Liga 2021-2022, Real Madrid recieves 86 points and Barcelon recieves 73 points.\n",
      "In La Liga 2021-2022, Real Madrid and Barcelona both recieve 3 points from the games between them.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "In La Liga 2021-2022, Real Madrid ranks higher than Barcelona.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "TEXT:\tA La Liga soccer team ranks higher than another if it receives more points.\n",
      "FOL:\tall x. all y. (LaLiga(x) & LaLiga(y) & MorePoints(x, y) -> HigherRank(x, y))\n",
      "TEXT:\tIf two La Liga soccer teams recieve the same points, the team which recieves more points from the games between the two teams ranks higher.\n",
      "FOL:\tall x. all y. (LaLiga(x) & LaLiga(y) & -MorePoints(x, y) & -MorePoints(y, x) & MorePointsInGameBetween(x, y) -> HigherRank(x, y))\n",
      "TEXT:\tReal Madrid and Barcelona are both La Liga soccer teams.\n",
      "FOL:\tLaLiga(RealMadrid) & LaLiga(Barcelona)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid recieves 86 points and Barcelon recieves 73 points.\n",
      "FOL:\tMorePoints(RealMadrid, Barcelona)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid and Barcelona both recieve 3 points from the games between them.\n",
      "FOL:\t-MorePointsInGameBetween(RealMadrid, Barcelona) & -MorePointsInGameBetween(Barcelona, RealMadrid)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid ranks higher than Barcelona.\n",
      "FOL:\tHigherRank(RealMadrid, Barcelona)\n",
      "</EVALUATE>\n",
      "\n",
      "<PREMISES>\n",
      "The bear eats the dog.\n",
      "The bear eats the rabbit.\n",
      "The bear is round.\n",
      "The bear needs the rabbit.\n",
      "The bear needs the tiger.\n",
      "The bear sees the rabbit.\n",
      "The dog eats the bear.\n",
      "The rabbit eats the tiger.\n",
      "The rabbit is round.\n",
      "The tiger eats the bear.\n",
      "The tiger is cold.\n",
      "The tiger is young.\n",
      "If something eats the tiger then the tiger needs the dog.\n",
      "If the bear sees the dog and the dog eats the tiger then the dog eats the bear.\n",
      "If something eats the bear then it sees the tiger.\n",
      "If the tiger sees the rabbit then the rabbit eats the bear.\n",
      "If something eats the bear and the bear sees the rabbit then it sees the dog.\n",
      "If something sees the dog then it sees the rabbit.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "The tiger eats the dog.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(task.get_prompt(task.get_dataset()[0]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "def get_args():\n",
    "    runner_args = RunnerArguments()\n",
    "    hf_args = HFArguments()\n",
    "    oai_args = OAIArguments()\n",
    "    gen_args = GenerationArguments()\n",
    "    args = HfArgumentParser([runner_args, hf_args, oai_args, gen_args]).parse_args(\"\")\n",
    "\n",
    "    args.output_dir = pathlib.Path(os.getcwd()).parent / args.output_dir\n",
    "    args.save_generations_raw_path = args.output_dir / args.save_generations_raw_path\n",
    "    args.save_generations_prc_path = args.output_dir / args.save_generations_prc_path\n",
    "    args.save_references_path = args.output_dir / args.save_references_path\n",
    "    args.save_results_path = args.output_dir / args.save_results_path\n",
    "    args.save_generations_raw_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    args.save_generations_prc_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    args.save_references_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    args.save_results_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    args.max_length_generation = 4096\n",
    "\n",
    "    args.openai_api_env_keys = ['OPENAI_API_KEY']\n",
    "    args.model = 'gpt-3.5-turbo'\n",
    "    return args"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "args = get_args()\n",
    "task = get_task('proofwriter-neurosymbolic-2shot')\n",
    "evaluator = OAIEvaluator(args, chat=True)\n",
    "dataset = task.get_dataset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant that carefully follows instructions. You should complete the user text, continuing from the example format, rather than providing a conversational response.\n"
     ]
    }
   ],
   "source": [
    "print(args.chat_system_instruction)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "ename": "InvalidRequestError",
     "evalue": "This model's maximum context length is 4097 tokens. However, you requested 5161 tokens (1065 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mInvalidRequestError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_completion\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43mprompt\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_prompt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtask\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstop_words\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/Chain-of-Context/eval/evaluator.py:188\u001B[0m, in \u001B[0;36mOAIEvaluator.get_completion\u001B[0;34m(self, prompt, stop, api_key, exhausted, retry_after)\u001B[0m\n\u001B[1;32m    186\u001B[0m openai\u001B[38;5;241m.\u001B[39mapi_key \u001B[38;5;241m=\u001B[39m api_key\n\u001B[1;32m    187\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 188\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_request\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    189\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m openai\u001B[38;5;241m.\u001B[39merror\u001B[38;5;241m.\u001B[39mRateLimitError:\n\u001B[1;32m    190\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_keys) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/projects/Chain-of-Context/eval/evaluator.py:140\u001B[0m, in \u001B[0;36mOAIEvaluator.make_request\u001B[0;34m(self, prompt, stop)\u001B[0m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmake_request\u001B[39m(\u001B[38;5;28mself\u001B[39m, prompt, stop):\n\u001B[1;32m    139\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchat:\n\u001B[0;32m--> 140\u001B[0m         response \u001B[38;5;241m=\u001B[39m \u001B[43mopenai\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mChatCompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    142\u001B[0m \u001B[43m            \u001B[49m\u001B[43mn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mn_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    143\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmessages\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\n\u001B[1;32m    144\u001B[0m \u001B[43m                \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msystem\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchat_system_instruction\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    145\u001B[0m \u001B[43m                \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrole\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43muser\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcontent\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mprompt\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    146\u001B[0m \u001B[43m            \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    147\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtemperature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    148\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmax_tokens\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_length_generation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtop_p\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtop_p\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    153\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    154\u001B[0m         response \u001B[38;5;241m=\u001B[39m openai\u001B[38;5;241m.\u001B[39mCompletion\u001B[38;5;241m.\u001B[39mcreate(\n\u001B[1;32m    155\u001B[0m             engine\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel,\n\u001B[1;32m    156\u001B[0m             n\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39margs\u001B[38;5;241m.\u001B[39mn_samples,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    162\u001B[0m             stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    163\u001B[0m         )\n",
      "File \u001B[0;32m~/Installation/Miniconda/miniconda3/envs/linc/lib/python3.10/site-packages/openai/api_resources/chat_completion.py:25\u001B[0m, in \u001B[0;36mChatCompletion.create\u001B[0;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m     24\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 25\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m TryAgain \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     27\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m>\u001B[39m start \u001B[38;5;241m+\u001B[39m timeout:\n",
      "File \u001B[0;32m~/Installation/Miniconda/miniconda3/envs/linc/lib/python3.10/site-packages/openai/api_resources/abstract/engine_api_resource.py:153\u001B[0m, in \u001B[0;36mEngineAPIResource.create\u001B[0;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001B[0m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcreate\u001B[39m(\n\u001B[1;32m    129\u001B[0m     \u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    136\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams,\n\u001B[1;32m    137\u001B[0m ):\n\u001B[1;32m    138\u001B[0m     (\n\u001B[1;32m    139\u001B[0m         deployment_id,\n\u001B[1;32m    140\u001B[0m         engine,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    150\u001B[0m         api_key, api_base, api_type, api_version, organization, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams\n\u001B[1;32m    151\u001B[0m     )\n\u001B[0;32m--> 153\u001B[0m     response, _, api_key \u001B[38;5;241m=\u001B[39m \u001B[43mrequestor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    154\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpost\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    155\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    156\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    157\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    158\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    159\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    160\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrequest_timeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    161\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m stream:\n\u001B[1;32m    164\u001B[0m         \u001B[38;5;66;03m# must be an iterator\u001B[39;00m\n\u001B[1;32m    165\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response, OpenAIResponse)\n",
      "File \u001B[0;32m~/Installation/Miniconda/miniconda3/envs/linc/lib/python3.10/site-packages/openai/api_requestor.py:226\u001B[0m, in \u001B[0;36mAPIRequestor.request\u001B[0;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mrequest\u001B[39m(\n\u001B[1;32m    206\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    207\u001B[0m     method,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    214\u001B[0m     request_timeout: Optional[Union[\u001B[38;5;28mfloat\u001B[39m, Tuple[\u001B[38;5;28mfloat\u001B[39m, \u001B[38;5;28mfloat\u001B[39m]]] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    215\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001B[38;5;28mbool\u001B[39m, \u001B[38;5;28mstr\u001B[39m]:\n\u001B[1;32m    216\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrequest_raw(\n\u001B[1;32m    217\u001B[0m         method\u001B[38;5;241m.\u001B[39mlower(),\n\u001B[1;32m    218\u001B[0m         url,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    224\u001B[0m         request_timeout\u001B[38;5;241m=\u001B[39mrequest_timeout,\n\u001B[1;32m    225\u001B[0m     )\n\u001B[0;32m--> 226\u001B[0m     resp, got_stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m resp, got_stream, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapi_key\n",
      "File \u001B[0;32m~/Installation/Miniconda/miniconda3/envs/linc/lib/python3.10/site-packages/openai/api_requestor.py:620\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response\u001B[0;34m(self, result, stream)\u001B[0m\n\u001B[1;32m    612\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[1;32m    613\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_interpret_response_line(\n\u001B[1;32m    614\u001B[0m             line, result\u001B[38;5;241m.\u001B[39mstatus_code, result\u001B[38;5;241m.\u001B[39mheaders, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    615\u001B[0m         )\n\u001B[1;32m    616\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m parse_stream(result\u001B[38;5;241m.\u001B[39miter_lines())\n\u001B[1;32m    617\u001B[0m     ), \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    618\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    619\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\n\u001B[0;32m--> 620\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_interpret_response_line\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    621\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstatus_code\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    623\u001B[0m \u001B[43m            \u001B[49m\u001B[43mresult\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    624\u001B[0m \u001B[43m            \u001B[49m\u001B[43mstream\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    625\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[1;32m    626\u001B[0m         \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    627\u001B[0m     )\n",
      "File \u001B[0;32m~/Installation/Miniconda/miniconda3/envs/linc/lib/python3.10/site-packages/openai/api_requestor.py:683\u001B[0m, in \u001B[0;36mAPIRequestor._interpret_response_line\u001B[0;34m(self, rbody, rcode, rheaders, stream)\u001B[0m\n\u001B[1;32m    681\u001B[0m stream_error \u001B[38;5;241m=\u001B[39m stream \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124merror\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m resp\u001B[38;5;241m.\u001B[39mdata\n\u001B[1;32m    682\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m stream_error \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;241m200\u001B[39m \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m rcode \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m300\u001B[39m:\n\u001B[0;32m--> 683\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandle_error_response(\n\u001B[1;32m    684\u001B[0m         rbody, rcode, resp\u001B[38;5;241m.\u001B[39mdata, rheaders, stream_error\u001B[38;5;241m=\u001B[39mstream_error\n\u001B[1;32m    685\u001B[0m     )\n\u001B[1;32m    686\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "\u001B[0;31mInvalidRequestError\u001B[0m: This model's maximum context length is 4097 tokens. However, you requested 5161 tokens (1065 in the messages, 4096 in the completion). Please reduce the length of the messages or completion."
     ]
    }
   ],
   "source": [
    "response = evaluator.get_completion(\n",
    "    prompt=task.get_prompt(dataset[0]),\n",
    "    stop=task.stop_words\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manually checking the improvement of technique"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc is  {'id': 'RelNoneg-OWA-D5-651', 'QDep': 0, 'premises': ['The bear eats the dog.', 'The bear eats the rabbit.', 'The bear is round.', 'The bear needs the rabbit.', 'The bear needs the tiger.', 'The bear sees the rabbit.', 'The dog eats the bear.', 'The rabbit eats the tiger.', 'The rabbit is round.', 'The tiger eats the bear.', 'The tiger is cold.', 'The tiger is young.', 'If something eats the tiger then the tiger needs the dog.', 'If the bear sees the dog and the dog eats the tiger then the dog eats the bear.', 'If something eats the bear then it sees the tiger.', 'If the tiger sees the rabbit then the rabbit eats the bear.', 'If something eats the bear and the bear sees the rabbit then it sees the dog.', 'If something sees the dog then it sees the rabbit.'], 'conclusion': 'The tiger eats the dog.', 'label': 'Uncertain'}\n"
     ]
    }
   ],
   "source": [
    "task = get_task('proofwriter-neurosymbolic-2shot')\n",
    "\n",
    "idx = 0\n",
    "\n",
    "doc = task.get_dataset()[idx]\n",
    "\n",
    "print(\"doc is \", doc)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following is a first-order logic (FOL) problem.\n",
      "The problem is to determine whether the conclusion follows from the premises.\n",
      "The premises are given in the form of a set of first-order logic sentences.\n",
      "The conclusion is given in the form of a single first-order logic sentence.\n",
      "The task is to translate each of the premises and conclusions into FOL expressions, so that the expressions can be evaluated by a theorem solver to determine whether the conclusion follows from the premises.\n",
      "Expressions should be adhere to the format of the Python NLTK package logic module.\n",
      "\n",
      "\n",
      "<PREMISES>\n",
      "All dispensable things are environment-friendly.\n",
      "All woodware is dispensable.\n",
      "All paper is woodware.\n",
      "No good things are bad.\n",
      "All environment-friendly things are good.\n",
      "A worksheet is either paper or is environment-friendly.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "A worksheet is not dispensable.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "TEXT:\tAll dispensable things are environment-friendly.\n",
      "FOL:\tall x. (Dispensable(x) -> EnvironmentFriendly(x))\n",
      "TEXT:\tAll woodware is dispensable.\n",
      "FOL:\tall x. (Woodware(x) -> Dispensable(x))\n",
      "TEXT:\tAll paper is woodware.\n",
      "FOL:\tall x. (Paper(x) -> Woodware(x))\n",
      "TEXT:\tNo good things are bad.\n",
      "FOL:\tall x. (Good(x) -> -Bad(x))\n",
      "TEXT:\tAll environment-friendly things are good.\n",
      "FOL:\tall x. (EnvironmentFriendly(x) -> Good(x))\n",
      "TEXT:\tA worksheet is either paper or is environment-friendly.\n",
      "FOL:\t((Paper(Worksheet) & -EnvironmentFriendly(Worksheet)) | (-Paper(Worksheet) & EnvironmentFriendly(Worksheet)))\n",
      "TEXT:\tA worksheet is not dispensable.\n",
      "FOL:\t-Dispensable(Worksheet)\n",
      "</EVALUATE>\n",
      "\n",
      "<PREMISES>\n",
      "A La Liga soccer team ranks higher than another if it receives more points.\n",
      "If two La Liga soccer teams recieve the same points, the team which recieves more points from the games between the two teams ranks higher.\n",
      "Real Madrid and Barcelona are both La Liga soccer teams.\n",
      "In La Liga 2021-2022, Real Madrid recieves 86 points and Barcelon recieves 73 points.\n",
      "In La Liga 2021-2022, Real Madrid and Barcelona both recieve 3 points from the games between them.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "In La Liga 2021-2022, Real Madrid ranks higher than Barcelona.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "TEXT:\tA La Liga soccer team ranks higher than another if it receives more points.\n",
      "FOL:\tall x. all y. (LaLiga(x) & LaLiga(y) & MorePoints(x, y) -> HigherRank(x, y))\n",
      "TEXT:\tIf two La Liga soccer teams recieve the same points, the team which recieves more points from the games between the two teams ranks higher.\n",
      "FOL:\tall x. all y. (LaLiga(x) & LaLiga(y) & -MorePoints(x, y) & -MorePoints(y, x) & MorePointsInGameBetween(x, y) -> HigherRank(x, y))\n",
      "TEXT:\tReal Madrid and Barcelona are both La Liga soccer teams.\n",
      "FOL:\tLaLiga(RealMadrid) & LaLiga(Barcelona)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid recieves 86 points and Barcelon recieves 73 points.\n",
      "FOL:\tMorePoints(RealMadrid, Barcelona)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid and Barcelona both recieve 3 points from the games between them.\n",
      "FOL:\t-MorePointsInGameBetween(RealMadrid, Barcelona) & -MorePointsInGameBetween(Barcelona, RealMadrid)\n",
      "TEXT:\tIn La Liga 2021-2022, Real Madrid ranks higher than Barcelona.\n",
      "FOL:\tHigherRank(RealMadrid, Barcelona)\n",
      "</EVALUATE>\n",
      "\n",
      "<PREMISES>\n",
      "The bear eats the dog.\n",
      "The bear eats the rabbit.\n",
      "The bear is round.\n",
      "The bear needs the rabbit.\n",
      "The bear needs the tiger.\n",
      "The bear sees the rabbit.\n",
      "The dog eats the bear.\n",
      "The rabbit eats the tiger.\n",
      "The rabbit is round.\n",
      "The tiger eats the bear.\n",
      "The tiger is cold.\n",
      "The tiger is young.\n",
      "If something eats the tiger then the tiger needs the dog.\n",
      "If the bear sees the dog and the dog eats the tiger then the dog eats the bear.\n",
      "If something eats the bear then it sees the tiger.\n",
      "If the tiger sees the rabbit then the rabbit eats the bear.\n",
      "If something eats the bear and the bear sees the rabbit then it sees the dog.\n",
      "If something sees the dog then it sees the rabbit.\n",
      "</PREMISES>\n",
      "<CONCLUSION>\n",
      "The tiger eats the dog.\n",
      "</CONCLUSION>\n",
      "<EVALUATE>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previous_prompt = task.get_prompt(doc)\n",
    "print(previous_prompt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEXT:\tThe bear eats the dog.\n",
      "FOL:\tEats(Bear, Dog)\n",
      "TEXT:\tThe bear eats the rabbit.\n",
      "FOL:\tEats(Bear, Rabbit)\n",
      "TEXT:\tThe bear is round.\n",
      "FOL:\tRound(Bear)\n",
      "TEXT:\tThe bear needs the rabbit.\n",
      "FOL:\tNeeds(Bear, Rabbit)\n",
      "TEXT:\tThe bear needs the tiger.\n",
      "FOL:\tNeeds(Bear, Tiger)\n",
      "TEXT:\tThe bear sees the rabbit.\n",
      "FOL:\tSees(Bear, Rabbit)\n",
      "TEXT:\tThe dog eats the bear.\n",
      "FOL:\tEats(Dog, Bear)\n",
      "TEXT:\tThe rabbit eats the tiger.\n",
      "FOL:\tEats(Rabbit, Tiger)\n",
      "TEXT:\tThe rabbit is round.\n",
      "FOL:\tRound(Rabbit)\n",
      "TEXT:\tThe tiger eats the bear.\n",
      "FOL:\tEats(Tiger, Bear)\n",
      "TEXT:\tThe tiger is cold.\n",
      "FOL:\tCold(Tiger)\n",
      "TEXT:\tThe tiger is young.\n",
      "FOL:\tYoung(Tiger)\n",
      "TEXT:\tIf something eats the tiger then the tiger needs the dog.\n",
      "FOL:\tall x. (Eats(x, Tiger) -> Needs(Tiger, Dog))\n",
      "TEXT:\tIf the bear sees the dog and the dog eats the tiger then the dog eats the bear.\n",
      "FOL:\tall x. all y. (Sees(Bear, Dog) & Eats(Dog, Tiger) -> Eats(Dog, Bear))\n",
      "TEXT:\tIf something eats the bear then it sees the tiger.\n",
      "FOL:\tall x. (Eats(x, Bear) -> Sees(x, Tiger))\n",
      "TEXT:\tIf the tiger sees the rabbit then the rabbit eats the bear.\n",
      "FOL:\tall x. (Sees(Tiger, Rabbit) -> Eats(Rabbit, Bear))\n",
      "TEXT:\tIf something eats the bear and the bear sees the rabbit then it sees the dog.\n",
      "FOL:\tall x. (Eats(x, Bear) & Sees(Bear, Rabbit) -> Sees(x, Dog))\n",
      "TEXT:\tIf something sees the dog then it sees the rabbit.\n",
      "FOL:\tall x. (Sees(x, Dog) -> Sees(x, Rabbit))\n",
      "TEXT:\tThe tiger eats the dog.\n",
      "FOL:\tEats(Tiger, Dog)\n",
      "\n",
      "Premise: The bear is an animal.\n",
      "FOL: Animal(Bear)\n",
      "Premise: The dog is an animal.\n",
      "FOL: Animal(Dog)\n",
      "\n",
      "Premise: The rabbit is an animal.\n",
      "FOL: Animal(Rabbit)\n",
      "\n",
      "Premise: The tiger is an animal.\n",
      "FOL: Animal(Tiger)\n",
      "\n",
      "Premise: Animals can eat other animals.\n",
      "FOL: all x. all y. (Animal(x) & Animal(y) -> CanEat(x, y))\n",
      "\n",
      "Premise: Seeing an animal implies the existence of that animal.\n",
      "FOL: all x. all y. (Sees(x, y) & Animal(y) -> Exists(y))\n",
      "\n",
      "Premise: Needing something implies its existence.\n",
      "FOL: all x. all y. (Needs(x, y) -> Exists(y))\n",
      "\n",
      "Premise: If an animal eats another, the eaten animal exists.\n",
      "FOL: all x. all y. (Eats(x, y) & Animal(y) -> Exists(y))\n",
      "\n",
      "Premise: Being round is a physical attribute.\n",
      "FOL: all x. (Round(x) -> HasPhysicalAttribute(x))\n",
      "\n",
      "Premise: Being cold is a physical state.\n",
      "FOL: all x. (Cold(x) -> HasPhysicalState(x))\n",
      "\n",
      "Premise: Being young is a temporal state.\n",
      "FOL: all x. (Young(x) -> HasTemporalState(x))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "previous_generation_raw = f\"\"\"\n",
    "TEXT:\tThe bear eats the dog.\n",
    "FOL:\tEats(Bear, Dog)\n",
    "TEXT:\tThe bear eats the rabbit.\n",
    "FOL:\tEats(Bear, Rabbit)\n",
    "TEXT:\tThe bear is round.\n",
    "FOL:\tRound(Bear)\n",
    "TEXT:\tThe bear needs the rabbit.\n",
    "FOL:\tNeeds(Bear, Rabbit)\n",
    "TEXT:\tThe bear needs the tiger.\n",
    "FOL:\tNeeds(Bear, Tiger)\n",
    "TEXT:\tThe bear sees the rabbit.\n",
    "FOL:\tSees(Bear, Rabbit)\n",
    "TEXT:\tThe dog eats the bear.\n",
    "FOL:\tEats(Dog, Bear)\n",
    "TEXT:\tThe rabbit eats the tiger.\n",
    "FOL:\tEats(Rabbit, Tiger)\n",
    "TEXT:\tThe rabbit is round.\n",
    "FOL:\tRound(Rabbit)\n",
    "TEXT:\tThe tiger eats the bear.\n",
    "FOL:\tEats(Tiger, Bear)\n",
    "TEXT:\tThe tiger is cold.\n",
    "FOL:\tCold(Tiger)\n",
    "TEXT:\tThe tiger is young.\n",
    "FOL:\tYoung(Tiger)\n",
    "TEXT:\tIf something eats the tiger then the tiger needs the dog.\n",
    "FOL:\tall x. (Eats(x, Tiger) -> Needs(Tiger, Dog))\n",
    "TEXT:\tIf the bear sees the dog and the dog eats the tiger then the dog eats the bear.\n",
    "FOL:\tall x. all y. (Sees(Bear, Dog) & Eats(Dog, Tiger) -> Eats(Dog, Bear))\n",
    "TEXT:\tIf something eats the bear then it sees the tiger.\n",
    "FOL:\tall x. (Eats(x, Bear) -> Sees(x, Tiger))\n",
    "TEXT:\tIf the tiger sees the rabbit then the rabbit eats the bear.\n",
    "FOL:\tall x. (Sees(Tiger, Rabbit) -> Eats(Rabbit, Bear))\n",
    "TEXT:\tIf something eats the bear and the bear sees the rabbit then it sees the dog.\n",
    "FOL:\tall x. (Eats(x, Bear) & Sees(Bear, Rabbit) -> Sees(x, Dog))\n",
    "TEXT:\tIf something sees the dog then it sees the rabbit.\n",
    "FOL:\tall x. (Sees(x, Dog) -> Sees(x, Rabbit))\n",
    "TEXT:\tThe tiger eats the dog.\n",
    "FOL:\tEats(Tiger, Dog)\n",
    "\"\"\"\n",
    "\n",
    "new_generation_raw = previous_generation_raw + f\"\"\"\n",
    "Premise: The bear is an animal.\n",
    "FOL: Animal(Bear)\n",
    "Premise: The dog is an animal.\n",
    "FOL: Animal(Dog)\n",
    "\n",
    "Premise: The rabbit is an animal.\n",
    "FOL: Animal(Rabbit)\n",
    "\n",
    "Premise: The tiger is an animal.\n",
    "FOL: Animal(Tiger)\n",
    "\n",
    "Premise: Animals can eat other animals.\n",
    "FOL: all x. all y. (Animal(x) & Animal(y) -> CanEat(x, y))\n",
    "\n",
    "Premise: Seeing an animal implies the existence of that animal.\n",
    "FOL: all x. all y. (Sees(x, y) & Animal(y) -> Exists(y))\n",
    "\n",
    "Premise: Needing something implies its existence.\n",
    "FOL: all x. all y. (Needs(x, y) -> Exists(y))\n",
    "\n",
    "Premise: If an animal eats another, the eaten animal exists.\n",
    "FOL: all x. all y. (Eats(x, y) & Animal(y) -> Exists(y))\n",
    "\n",
    "Premise: Being round is a physical attribute.\n",
    "FOL: all x. (Round(x) -> HasPhysicalAttribute(x))\n",
    "\n",
    "Premise: Being cold is a physical state.\n",
    "FOL: all x. (Cold(x) -> HasPhysicalState(x))\n",
    "\n",
    "Premise: Being young is a temporal state.\n",
    "FOL: all x. (Young(x) -> HasTemporalState(x))\n",
    "\"\"\"\n",
    "print(new_generation_raw)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reference:  Uncertain\n",
      "without context:  Uncertain\n",
      "with context:  Uncertain\n"
     ]
    }
   ],
   "source": [
    "print(\"reference: \", task.get_reference(doc))\n",
    "print(\"without context: \", task.postprocess_generation(previous_generation_raw, idx, completion_only=True))\n",
    "print(\"with context: \", task.postprocess_generation(new_generation_raw, idx, completion_only=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "4096"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.max_length_generation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TEXT:\tThe bear eats the dog.\n",
      "FOL:\tEats(Bear, Dog)\n",
      "TEXT:\tThe bear eats the rabbit.\n",
      "FOL:\tEats(Bear, Rabbit)\n",
      "TEXT:\tThe bear is round.\n",
      "FOL:\tRound(Bear)\n",
      "TEXT:\tThe bear needs the rabbit.\n",
      "FOL:\tNeeds(Bear, Rabbit)\n",
      "TEXT:\tThe bear needs the tiger.\n",
      "FOL:\tNeeds(Bear, Tiger)\n",
      "TEXT:\tThe bear sees the rabbit.\n",
      "FOL:\tSees(Bear, Rabbit)\n",
      "TEXT:\tThe dog eats the bear.\n",
      "FOL:\tEats(Dog, Bear)\n",
      "TEXT:\tThe rabbit eats the tiger.\n",
      "FOL:\tEats(Rabbit, Tiger)\n",
      "TEXT:\tThe rabbit is round.\n",
      "FOL:\tRound(Rabbit)\n",
      "TEXT:\tThe tiger eats the bear.\n",
      "FOL:\tEats(Tiger, Bear)\n",
      "TEXT:\tThe tiger is cold.\n",
      "FOL:\tCold(Tiger)\n",
      "TEXT:\tThe tiger is young.\n",
      "FOL:\tYoung(Tiger)\n",
      "TEXT:\tIf something eats the tiger then the tiger needs the dog.\n",
      "FOL:\tall x. (Eats(x, Tiger) -> Needs(Tiger, Dog))\n",
      "TEXT:\tIf the bear sees the dog and the dog eats the tiger then the dog eats the bear.\n",
      "FOL:\tall x. all y. (Sees(Bear, Dog) & Eats(Dog, Tiger) -> Eats(Dog, Bear))\n",
      "TEXT:\tIf something eats the bear then it sees the tiger.\n",
      "FOL:\tall x. (Eats(x, Bear) -> Sees(x, Tiger))\n",
      "TEXT:\tIf the tiger sees the rabbit then the rabbit eats the bear.\n",
      "FOL:\tall x. (Sees(Tiger, Rabbit) -> Eats(Rabbit, Bear))\n",
      "TEXT:\tIf something eats the bear and the bear sees the rabbit then it sees the dog.\n",
      "FOL:\tall x. (Eats(x, Bear) & Sees(Bear, Rabbit) -> Sees(x, Dog))\n",
      "TEXT:\tIf something sees the dog then it sees the rabbit.\n",
      "FOL:\tall x. (Sees(x, Dog) -> Sees(x, Rabbit))\n",
      "TEXT:\tThe tiger eats the dog.\n",
      "FOL:\tEats(Tiger, Dog)\n",
      "\n",
      "Premise: The bear is an animal.\n",
      "FOL: Animal(Bear)\n",
      "Premise: The dog is an animal.\n",
      "FOL: Animal(Dog)\n",
      "\n",
      "Premise: The rabbit is an animal.\n",
      "FOL: Animal(Rabbit)\n",
      "\n",
      "Premise: The tiger is an animal.\n",
      "FOL: Animal(Tiger)\n",
      "\n",
      "Premise: Animals can eat other animals.\n",
      "FOL: all x. all y. (Animal(x) & Animal(y) -> CanEat(x, y))\n",
      "\n",
      "Premise: Seeing an animal implies the existence of that animal.\n",
      "FOL: all x. all y. (Sees(x, y) & Animal(y) -> Exists(y))\n",
      "\n",
      "Premise: Needing something implies its existence.\n",
      "FOL: all x. all y. (Needs(x, y) -> Exists(y))\n",
      "\n",
      "Premise: If an animal eats another, the eaten animal exists.\n",
      "FOL: all x. all y. (Eats(x, y) & Animal(y) -> Exists(y))\n",
      "\n",
      "Premise: Being round is a physical attribute.\n",
      "FOL: all x. (Round(x) -> HasPhysicalAttribute(x))\n",
      "\n",
      "Premise: Being cold is a physical state.\n",
      "FOL: all x. (Cold(x) -> HasPhysicalState(x))\n",
      "\n",
      "Premise: Being young is a temporal state.\n",
      "FOL: all x. (Young(x) -> HasTemporalState(x))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(new_generation_raw)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "linc-kernel",
   "language": "python",
   "display_name": "linc-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
